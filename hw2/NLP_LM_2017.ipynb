{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Домашнее задание №1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Тема: Языковое моделирование и определение языка.\n",
    "\n",
    "\n",
    "**Выдана**:   14 сентября 2017\n",
    "\n",
    "**Дедлайн**:   <font color='red'>9:00 утра 28 сентября 2017</font>\n",
    "\n",
    "**Среда выполнения**: Jupyter Notebook (Python 3)\n",
    "\n",
    "#### Правила:\n",
    "\n",
    "Результат выполнения задания $-$ отчет в формате Jupyter Notebook с кодом и выводами. В ходе выполнения задания требуется реализовать все необходимые алгоритмы, провести эксперименты и ответить на поставленные вопросы. Дополнительные выводы приветствуются. Чем меньше кода и больше комментариев $-$ тем лучше.\n",
    "\n",
    "Все ячейки должны быть \"выполненными\", при этом результат должен воспроизвдиться при проверке (на Python 3). Если какой-то код не был запущен или отрабатывает с ошибками, то пункт не засчитывается. Задание, сданное после дедлайна, _не принимается_. Совсем.\n",
    "\n",
    "\n",
    "Задание выполняется самостоятельно. Вы можете обсуждать идеи, объяснять друг другу материал, но не можете обмениваться частями своего кода. Если какие-то студенты будут уличены в списывании, все они автоматически получат за эту работу 0 баллов, а также предвзято негативное отношение семинаристов в будущем. Если вы нашли в Интернете какой-то код, который собираетесь заимствовать, обязательно укажите это в задании: вполне вероятно, что вы не единственный, кто найдёт и использует эту информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Постановка задачи:\n",
    "\n",
    "В данной лабораторной работе Вам предстоит реализовать n-грамную языковую модель с несколькими видами сглаживания:\n",
    "- Add-one smoothing\n",
    "- Stupid backoff\n",
    "- Interpolation smoothing\n",
    "- Kneser-Ney smoothing\n",
    "\n",
    "Вы обучите ее на готовых корпусах, оцените качество и проведете ряд экспериментов. Во второй части задания Вы примените реализованную модель (но с буквенными n-граммами) к задаче распознавания языка. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Цель языкового моделирования заключается в том, чтобы присвоить некоторые вероятности предложениям. Задача состоит в подсчете вероятности $P(W) = P(w_1, \\dots, w_n)$ или $P(w_n \\mid w_1, \\dots, w_{n-1})$. Модель, умеющая вычислять хотя бы одну из этих двух вероятностей, называется **языковой моделью** (LM от Language Model).\n",
    "\n",
    "Согласно **цепному правилу** (chain rule):\n",
    "\n",
    "$$P(X_1, \\dots, X_n) = P(X_1)P(X_2 \\mid X_1)\\dots P(X_n \\mid X_1, \\dots, X_{n-1}).$$ \n",
    "\n",
    "Также мы знаем, что\n",
    "\n",
    "$$\n",
    "    P(X_n \\mid X_1, \\dots, X_{n-1}) = \\frac{P(X_1, \\dots, X_n)}{P(X_1, \\dots, X_{n-1})},\n",
    "$$\n",
    "\n",
    "следовательно, для того чтобы оценить $P(X_n \\mid X_1, \\dots, X_{n-1})$ нужно посчитать $P(X_1, \\dots, X_n)$ и $P(X_1, \\dots, X_{n-1})$. Но эти вероятности будут чрезвычайно малы, если мы возьмем большое $n$, так множество предложений из $n$ слов растет экспоненциально. Для упрощения применим **марковское предположение**: \n",
    "\n",
    "$$P(X_n \\mid X_1, \\dots, X_{n-1}) = P(X_n \\mid X_{n - k + 1}, \\dots, X_{n-1})$$\n",
    "\n",
    "для некоторого фиксированного (небольшого) $k$. Это предположение говорит о том, что $X_{n}$ не зависит от $X_{1}, \\dots, X_{n - k}$, то есть на следующее слово влияет лишь контекст из предыдущих $k - 1$ слова. Таким образом, мы получаем финальную вероятность:\n",
    "\n",
    "$$\n",
    "    P(w_1, \\dots, w_n) = \\prod_i P(w_i \\mid w_{i-k+1}, \\dots, w_{i - 1}).\n",
    "$$\n",
    "\n",
    "Далее для краткости будем обозначать $w_{i-k}^i := w_{i-k}, \\dots, w_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Хранилище n-грам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для начала выполним вспомогательную работу. Следуйте комментариям, чтобы написать NGramStorage с удобным интерфейсом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NGramStorage:\n",
    "    \"\"\"Storage for ngrams' frequencies.\n",
    "    \n",
    "    Args:\n",
    "        sents (list[list[str]]): List of sentences from which ngram\n",
    "            frequencies are extracted.\n",
    "        max_n (int): Upper bound of the length of ngrams.\n",
    "            For instance if max_n = 2, then storage will store\n",
    "            0, 1, 2-grams.\n",
    "            \n",
    "    Attributes:\n",
    "        max_n (Readonly(int)): Upper bound of the length of ngrams.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __init__(self, sents=[], max_n=0):\n",
    "        self.__max_n = max_n\n",
    "        self.__ngrams = {i: Counter() for i in range(self.__max_n + 1)}\n",
    "        self.__v = 0\n",
    "        self.__different_pairs = 0\n",
    "        # self._ngrams[K] should have the following interface:\n",
    "        # self._ngrams[K][(w_1, ..., w_K)] = number of times w_1, ..., w_K occured in words\n",
    "        # self._ngrams[0][()] = number of all words\n",
    "        # self.__v = number of different words\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        \n",
    "        for sent in sents:\n",
    "            self.__ngrams[0][()] = self.__ngrams[0][()] + len(sent)\n",
    "            \n",
    "        different_words = set()\n",
    "        for sent in sents:\n",
    "            for word in sent:\n",
    "                different_words.add(word)\n",
    "        self.__v = len(different_words)\n",
    "        self.__diffent_words = different_words\n",
    "        \n",
    "        different_pairs = set()\n",
    "        for sent in sents:\n",
    "            for i in range(len(sent) - 1):\n",
    "                different_pairs.add((sent[i], sent[i + 1]))\n",
    "        self.__different_pairs = len(different_pairs)\n",
    "        \n",
    "        for i in range(1, self.__max_n + 1):\n",
    "            i_gramms = []\n",
    "            for sent in sents:\n",
    "                for start in range(len(sent) - i + 1):\n",
    "                    i_gramma = []\n",
    "                    for index in range(start, start + i):\n",
    "                        i_gramma.append(sent[index])\n",
    "                    i_gramms.append(tuple(i_gramma))\n",
    "            self.__ngrams[i] = Counter(i_gramms)\n",
    "\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "    def add_unk_token(self):\n",
    "        \"\"\"Add UNK token to 1-grams.\"\"\"\n",
    "        # In order to avoid zero probabilites \n",
    "        if self.__max_n == 0 or 'UNK' in self.__ngrams[1]:\n",
    "            return\n",
    "        self.__ngrams[0][()] += 1\n",
    "        self.__ngrams[1][('UNK', )] = 1\n",
    "        \n",
    "    @property\n",
    "    def max_n(self):\n",
    "        \"\"\"Get max_n\"\"\"\n",
    "        return self.__max_n\n",
    "        \n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Get dictionary of k-gram frequencies.\n",
    "        \n",
    "        Args:\n",
    "            k (int): length of returning ngrams' frequencies.\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary (in fact Counter) of k-gram frequencies.\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(k, int):\n",
    "            raise TypeError('k (length of ngrams) must be an integer!')\n",
    "        if k > self.__max_n:\n",
    "            raise ValueError('k (length of ngrams) must be less or equal to the maximal length!')\n",
    "        return self.__ngrams[k]\n",
    "    \n",
    "    def __call__(self, ngram):\n",
    "        \"\"\"Return frequency of a given ngram.\n",
    "        \n",
    "        Args:\n",
    "            ngram (tuple): ngram for which frequency should be computed.\n",
    "            \n",
    "        Returns:\n",
    "            Frequency (int) of a given ngram.\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(ngram, tuple):\n",
    "            raise TypeError('ngram must be a tuple!')\n",
    "        if len(ngram) > self.__max_n:\n",
    "            print(\"ngram length =\", len(ngram), \"max_n =\", self.__max_n)\n",
    "            raise ValueError('length of ngram must be less or equal to the maximal length!')\n",
    "        if len(ngram) == 1 and ngram not in self.__ngrams[1]:\n",
    "            return self.__ngrams[1][('UNK', )]\n",
    "        return self.__ngrams[len(ngram)][ngram]\n",
    "    \n",
    "    def get_v(self):\n",
    "        return self.__v\n",
    "    \n",
    "    def get_n_plus(self, context):\n",
    "        n_plus = 0\n",
    "        for word in self.__diffent_words:\n",
    "            if self(context + (word,)) > 0:\n",
    "                n_plus = n_plus + 1\n",
    "        return n_plus\n",
    "    \n",
    "    def get_c_sum(self, context):\n",
    "        c_sum = 0\n",
    "        for word in self.__diffent_words:\n",
    "            c_sum = c_sum + self(context + (word, ))\n",
    "        return c_sum\n",
    "    \n",
    "    def get_different_words(self):\n",
    "        return self.__diffent_words\n",
    "    \n",
    "    def get_different_pairs(self):\n",
    "        return self.__different_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to check new storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(): 7})\n",
      "Counter({('b',): 3, ('c',): 2, ('a',): 1, ('d',): 1})\n",
      "Counter({('b', 'c'): 2, ('c', 'b'): 1, ('b', 'd'): 1, ('a', 'b'): 1})\n",
      "Counter({('b', 'c', 'b'): 1, ('a', 'b', 'c'): 1, ('c', 'b', 'd'): 1})\n",
      "Counter({('b', 'c', 'b', 'd'): 1})\n",
      "2\n",
      "different words =  4\n",
      "2\n",
      "{'b', 'a', 'd', 'c'}\n"
     ]
    }
   ],
   "source": [
    "n_gram_storage = NGramStorage([[\"a\", \"b\", \"c\"], [\"b\", \"c\", \"b\", \"d\"]], 4)\n",
    "for i in range(5):\n",
    "    print(n_gram_storage[i])\n",
    "print(n_gram_storage(('b', 'c')))\n",
    "print(\"different words = \",n_gram_storage.get_v())\n",
    "print(n_gram_storage.get_n_plus((\"b\",)))\n",
    "print(n_gram_storage.get_different_words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Скачайте brown корпус, обучите модель и протестируйте на нескольких примерах последовательностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Uncomment next row and download brown corpus\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all sentences = 57340\n",
      "Number of train sentences = 45872\n",
      "Number of test sentences = 11468\n"
     ]
    }
   ],
   "source": [
    "all_sents = list(brown.sents())\n",
    "random.shuffle(all_sents)\n",
    "print('Number of all sentences = {}'.format(len(all_sents)))\n",
    "train_sents = all_sents[:int(0.8 * len(all_sents))]\n",
    "test_sents = all_sents[int(0.8 * len(all_sents)):]\n",
    "print('Number of train sentences = {}'.format(len(train_sents)))\n",
    "print('Number of test sentences = {}'.format(len(test_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create storage of 0, 1, 2, 3-grams\n",
    "storage = NGramStorage(train_sents, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1374\n",
      "3345\n",
      "23\n",
      "0\n",
      "930229\n"
     ]
    }
   ],
   "source": [
    "# It's time to test your code\n",
    "print(storage(('to', 'be')))\n",
    "print(storage(('or',)))\n",
    "print(storage(('not', 'to', 'be')))\n",
    "print(storage(('somethingweird',)))\n",
    "print(storage(()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Для численного измерения качества языковой модели определим **перплексию**:\n",
    "\n",
    "$$\n",
    "    {\\mathbb{P}}(w_1, \\dots, w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_i P(w_i \\mid w_{i - k}, \\dots, w_{i - 1})\\right)^{-\\frac1N},\n",
    "$$\n",
    "\n",
    "Вижно, что минимизация перплексии эквивалентна максимизации правдоподобия модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Реализуйте функцию по подсчету перплексии. Обратите внимание, что перплексия по корпусу равна произведению вероятностей **всех** предложений в степени $-\\frac1N$, где $N -$ суммарная длина всех предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def perplexity(estimator, sents):\n",
    "    '''Estimate perplexity of the sequence of words using prob_estimator.'''\n",
    "    ### YOUR CODE HERE\n",
    "    # Avoid log(0) by replacing zero by 10 ** (-50).\n",
    "    log_perp = 0\n",
    "    N = 0\n",
    "    for sent in sents:\n",
    "        N = N + len(sent)\n",
    "        p = estimator.prob(sent)\n",
    "        if p != 0:\n",
    "            log_p = math.log(p)\n",
    "        else:\n",
    "            log_p = math.log(10 ** (-200))\n",
    "        log_perp = log_perp + log_p\n",
    "    log_perp = - log_perp / N \n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return math.exp(log_perp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Оценка вероятностей n-грам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Первый и простейший способ оценки вероятностей N-грам следующий:\n",
    "\n",
    "$$\n",
    "    \\hat P_{S}(w_{N} \\mid w_1^{N - 1}) = \\frac{c(w_1^N)}{c(w_1^{N-1})}.\n",
    "$$\n",
    "\n",
    "где $c(w_1^N)$ — это число последовательностей $w_1, \\dots, w_N$ в корпусе, $S$ символизирует Straightforward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class StraightforwardProbabilityEstimator:\n",
    "    \"\"\"Class for simplest probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = c(context + word) / c(context), where\n",
    "    c(sequence) - number of occurances of the sequence in the corpus.\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage):\n",
    "        self.__storage = storage\n",
    "        # Adding UNK token to avoid zero probabilities\n",
    "        self.__storage.add_unk_token()\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if self.__storage.max_n == 1:\n",
    "            return ()\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            return context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, str):\n",
    "            print(type(word))\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('word must be a string!')\n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        phrase_counts = self.__storage(context + (word, ))\n",
    "        context_counts = self.__storage(context)\n",
    "        # Avoiding 0 / 0.\n",
    "        if context_counts == 0:\n",
    "            return 0.\n",
    "        return 1. * phrase_counts / context_counts\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 4487270591.962576\n",
      "1.7200047300130075e-05\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "simple_estimator = StraightforwardProbabilityEstimator(storage)\n",
    "\n",
    "# Estimating perplexity\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(simple_estimator, test_sents)))\n",
    "print(simple_estimator.prob('To be'.split()))\n",
    "print(simple_estimator.prob('To be or not to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Посчитаем перплексию униграмной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 1312.6517628813137\n",
      "2.0331683001304758e-06\n",
      "3.3182592001334663e-15\n"
     ]
    }
   ],
   "source": [
    "uni_storage = NGramStorage(train_sents, 1)\n",
    "uni_simple_estimator = StraightforwardProbabilityEstimator(uni_storage)\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(uni_simple_estimator, test_sents)))\n",
    "print(uni_simple_estimator.prob('To be'.split()))\n",
    "print(uni_simple_estimator.prob('To be or not to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ответьте на следующие вопросы (внутри ipython ноутбука):\n",
    "\n",
    "**Q:** Какие выводы можно сделать? Почему $P(\\text{To be or not to be}) = 0$, хотя мы и добавили UNK токен?  \n",
    "**A:** Униграмная модель хуже трехграмной, так как ее перплексия больше. Почему $P(\\text{To be or not to be}) = 0$, хотя мы и добавили UNK токен, потому что UNK токен введен только для 1-грамм, а, например, \"To be or\" тоже не встречается в тексте. (что собственно демонстрирует нам вывод для униграммной модели, где токен UNK помогает избежать нулей)\n",
    "\n",
    "**Q:** Почему перплексия униграмной модели меньше, чем триграмной?  \n",
    "**A:** Перплексия трехграмной модели взрывается (если правильно заменять вероятность 0 на что-то очень маленькое), так как там есть нули. (то есть деление на 0!) А в униграммных нет такой проблемы из-за токена UNK (тк там нет деления на 0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Add-one smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Простейший вид сглаживания — **сглаживание Лапласа**. Чтобы избавиться от нулевых вероятностей $P(w_{N} \\mid w_1^{N - 1})$, будем использовать формулу:\n",
    "\n",
    "$$\n",
    "    \\hat P_{AOS}(w_{N} \\mid w_1^{N - 1}) = \\frac{c(w_1^N) + \\delta}{c(w_1^{N-1}) + \\delta V},\n",
    "$$\n",
    "\n",
    "где $V$ — это размер словаря, а $\\delta$ — некоторая фиксированная константа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Реализуйте класс, осуществляющий сглаживание Лапласа. Он должен иметь аналогичный интерфейс, как и StraightforwardProbabilityEstimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class LaplaceProbabilityEstimator:\n",
    "    \"\"\"Class for probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = (c(context + word) + delta) / (c(context) + delta * V), where\n",
    "    c(sequence) - number of occurances of the sequence in the corpus,\n",
    "    delta - some constant,\n",
    "    V - number of different words in corpus.\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "        delta(float): Smoothing parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage, delta=1.):\n",
    "        self.__storage = storage\n",
    "        self.__delta = delta\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if self.__storage.max_n == 1:\n",
    "            return ()\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            return context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, str):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('context must be a tuple!')\n",
    "            \n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        phrase_counts = self.__storage(context + (word, ))\n",
    "        context_counts = self.__storage(context)\n",
    "        v = self.__storage.get_v()\n",
    "        return 1. * (phrase_counts + self.__delta) \\\n",
    "            / (context_counts + 1. * self.__delta * v)\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Подберите наилучший параметр $\\delta$ для данного корпуса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пройдемя по дельтам от 0 до 1. Нарисуем график перплексии от дельты и возьмем минимум, так как чем меньше перплексия тем лучше. Все это сделаем для униграмной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try to find out best delta parameter. We will not provide you any strater code.\n",
    "DELTA = [0.0001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]\n",
    "perp = []\n",
    "for delta in DELTA:\n",
    "    laplace_estomator = LaplaceProbabilityEstimator(uni_storage, delta)\n",
    "    perp.append(perplexity(laplace_estomator, test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1314.1006304253483\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAFdCAYAAACuO39sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe97828e208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(DELTA, perp, 'ro')\n",
    "plt.xlim([0, 1])\n",
    "print(max(perp))\n",
    "plt.ylim([min(perp) - 10, max(perp) + 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь для трехграмной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to find out best delta parameter. We will not provide you any strater code.\n",
    "DELTA = [0.0001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99]\n",
    "perp = []\n",
    "for delta in DELTA:\n",
    "    laplace_estomator = LaplaceProbabilityEstimator(storage, delta)\n",
    "    perp.append(perplexity(laplace_estomator, test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAFdCAYAAADVH72gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe978289908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(DELTA, perp, 'ro')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([min(perp) - 10, max(perp) + 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше получилась все еще униграмная модель с delta = 0.4. Но нас попросили посчитать с для трехграмной (вроде), так что тут дельта очень близко к нулю, посмотрим, что будет при дельта ближе к нулю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try to find out best delta parameter. We will not provide you any strater code.\n",
    "DELTA = [10 ** (-6), 10 ** (-5), 10 ** (-4), 10 ** (-3), 10 ** (-2), 10 ** (-1)]\n",
    "perp = []\n",
    "for delta in DELTA:\n",
    "    laplace_estomator = LaplaceProbabilityEstimator(storage, delta)\n",
    "    perp.append(perplexity(laplace_estomator, test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiYAAAFdCAYAAAA3w6bZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe97cbeea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(DELTA, perp, 'ro')\n",
    "plt.xlim([0, 10 ** (-1)])\n",
    "plt.ylim([min(perp) - 10, max(perp) + 10])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для трехграмной модели лучшее дельта, которое я нашла - 10 ** (-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_delta = 10 ** (-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace estimator perplexity = 8353.75911162099\n",
      "1.404562201008235e-05\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "laplace_estimator = LaplaceProbabilityEstimator(storage, best_delta)\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Laplace estimator perplexity = {}'.format(perplexity(laplace_estimator, test_sents)))\n",
    "print(laplace_estimator.prob('To be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Stupid backoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Идея **простого отката** довольно понятна. Если у нас есть достаточно информцаии для подсчета вероятности $k$-грам, то будем использовать $k$-грамы. Иначе будем использовать вероятности $(k-1)$-грам с некоторым множителем, например, $0.4$, и так далее. К сожалению, в данном случае мы получим не вероятностное распределение, но в большинстве задач это не имеет принципиального значения. Если это все же важно, то необходимо подобрать множитель соответствующим образом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Реализуйте класс, симулирующий сглаживание простым откатом. Он должен иметь аналогичный интерфейс, как и StraightforwardProbabilityEstimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class StupidBackoffProbabilityEstimator:\n",
    "    \"\"\"Class for stupid backoff probability estimations.\n",
    "    \n",
    "    P(word | context) =\n",
    "        P'(word | context),                  if  P'(word | context) > 0;\n",
    "        P'(word | context[1:]) * multiplier, if  P'(word | context) == 0\n",
    "                                             and P'(word | context[1:]) > 0;\n",
    "        ...\n",
    "    P'(word | context) - probability of a word provided context of a base estimator.\n",
    "    \n",
    "    Args:\n",
    "        base_estimator(BaseProbabilityEstimator): Object of BaseProbabilityEstimator\n",
    "            or some other class which can estimate conditional probabilities.\n",
    "        multiplier (float): Multiplier which is used for probability estimations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator, multiplier=0.1):\n",
    "        self.__base_estimator = base_estimator\n",
    "        self.__mult = multiplier\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        \n",
    "        # If context is too large, let's cut it.\n",
    "#         context = self.cut_context(context)\n",
    "        prob = self.__base_estimator(word, context)\n",
    "        mult = 1.\n",
    "        while prob == 0.:\n",
    "            context = context[1:]\n",
    "            prob = self.__base_estimator(word, context)\n",
    "            mult = mult * self.__mult\n",
    "        return prob * mult\n",
    "        \n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stupid backoff estimator perplexity = 154846.06426455657\n",
      "1.404562201008235e-05\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "sbackoff_estimator = StupidBackoffProbabilityEstimator(simple_estimator, .4)\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Stupid backoff estimator perplexity = {}'.format(perplexity(sbackoff_estimator, test_sents)))\n",
    "print(laplace_estimator.prob('To be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ответьте на следующие вопросы (внутри ipython ноутбука):\n",
    "\n",
    "**Q:** Почему бессмысленно измерять перплексию в случае **Stupid backoff**?  \n",
    "**A:** Ну... ее бессмысленно измерять, так как она точно будет меньше, чем у базового алгоритма, так как с помощью данного алгоритма мы по сути убираем нули...\n",
    "\n",
    "Возможно, еще потому, что с помощью перплексии мы смотрим насколько вероятна тестовая выборка при условии нашего трейна, но в данном случае мы просто \"подгоняем\" нашу тестовую выборку под трейн (так как ищем конкретные нграммы, которые точно были в трейне)...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Interpolation smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "В данном случае идея сглаживания посредством **интерполяции** также крайне проста. Пусть у нас есть $N$-грамная модель. Заведем вектор $\\bar\\lambda = (\\lambda_1, \\dots, \\lambda_N)$, такой, что $\\sum_i\\lambda_i = 1$ и $\\lambda_i \\geq 0$. Тогда\n",
    "\n",
    "$$\n",
    "    \\hat P_{IS}(w_{N} \\mid w_1^{N-1}) = \\sum_{i=1}^N \\lambda_i \\hat P_{S}(w_N \\mid w_{N-i+1}^{N-1}).\n",
    "$$\n",
    "\n",
    "Придумайте, как обойтись одним вектором $\\bar\\lambda$, т.е. пользоваться им как в случае контекста длины $N$, так и при контексте меньшей длины (например, в начале предложения). Если мы просто обрубим сумму, то у нас уже не будет вероятностное распределение, что, конечно же, плохо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея про то, как использовать тот же вектор: обрубить сумму + поделить на сумму оставшихся членов. Типа нормализовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class InterpolationProbabilityEstimator:\n",
    "    \"\"\"Class for interpolation probability estimations.\n",
    "    \n",
    "    P(word | context) =\n",
    "        lambda_N * P'(word | context) +\n",
    "        lambda_{N-1} * P'(word | context[1:]) +\n",
    "        ... +\n",
    "        lambda_1 * P'(word)\n",
    "    P'(word | context) - probability of a word provided context of a base estimator.\n",
    "    \n",
    "    Args:\n",
    "        base_estimator(BaseProbabilityEstimator): Object of BaseProbabilityEstimator\n",
    "            or some other class which can estimate conditional probabilities.\n",
    "        lambdas (np.array[float]): Lambdas which are used for probability estimations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator, lambdas):\n",
    "        self.__lambdas = lambdas\n",
    "        self.__base_estimator = base_estimator\n",
    "        self.__max_n = len(lambdas)\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        context = self.cut_context(context)\n",
    "        \n",
    "        k = len(context) + 1\n",
    "        lambdas = self.__lambdas[:k] / sum(self.__lambdas[:k])\n",
    "        prob = 0.\n",
    "        for i in range(k):\n",
    "            prob = prob + lambdas[i] * self.__base_estimator(word, context[i:])\n",
    "        return prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob\n",
    "    \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if self.__max_n == 1:\n",
    "            return ()\n",
    "        if len(context) + 1 > self.__max_n:\n",
    "            return context[-self.__max_n + 1:]\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation estimator perplexity = 629.4520941379807\n",
      "1.404562201008235e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize estimator\n",
    "interpol_estimator = InterpolationProbabilityEstimator(simple_estimator, np.array([0.2, 0.2, 0.6]))\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Interpolation estimator perplexity = {}'.format(perplexity(interpol_estimator, test_sents)))\n",
    "print(laplace_estimator.prob('To be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Обучить значения параметров $\\lambda$ можно с помощью EM-алгоритма, но мы не будем этого здесь делать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Kneser-Ney smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Идея данного сглаживания заключается в том, что словам, которые участвуют в большом количестве контекстов, присваиваются большие вероятности, а те, которые используются в паре-тройке контекстов, получают маленькие вероятности. Формулы приведены на слайде 37 лекции.\n",
    "Реализуйте данный подход."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class KneserNeyProbabilityEstimator:\n",
    "    \"\"\"Class for probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = ...\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "        delta(float): KneserNey parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage, delta=1.):\n",
    "        self.__storage = storage\n",
    "        self.__delta = delta\n",
    "        # storing the data so we don't have to calculate it often\n",
    "        self.__n_plus = {}\n",
    "        self.__c_sum = {}\n",
    "        # first/second = ratio for initial probability\n",
    "        self.__first = {}\n",
    "        self.__second = self.__storage.get_different_pairs()\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if self.__storage.max_n == 1:\n",
    "            return ()\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            return context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, str):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('word must be a string!')\n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        \n",
    "        if len(context) == 0:\n",
    "            if word in self.__first.keys():\n",
    "                return 1. * self.__first[word] / self.__second\n",
    "            else :\n",
    "                first = 0\n",
    "                diffrent_words = self.__storage.get_different_words()\n",
    "                for word_1 in diffrent_words:\n",
    "                    if self.__storage((word_1, word)) > 0:\n",
    "                        first = first + 1\n",
    "                self.__first[word] = first\n",
    "                return 1. * first / self.__second\n",
    "            \n",
    "        c_sum = 0\n",
    "        n_plus = 0\n",
    "        if context in self.__c_sum.keys():\n",
    "            c_sum = self.__c_sum[context]\n",
    "        else:\n",
    "            c_sum = self.__storage.get_c_sum(context)\n",
    "            self.__c_sum[context] = c_sum\n",
    "        if context in self.__n_plus.keys():\n",
    "            n_plus = self.__n_plus[context]\n",
    "        else:\n",
    "            n_plus = self.__storage.get_n_plus(context)\n",
    "            self.__n_plus[context] = n_plus\n",
    "        c = self.__storage(context + (word, ))\n",
    "        delta = self.__delta\n",
    "        if c_sum == 0:\n",
    "            return n_plus * self(word, context[1:])\n",
    "        prob = max(0, c - delta) / c_sum \\\n",
    "            + delta / c_sum * n_plus * self(word, context[1:])\n",
    "        return prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 360081054054.8754\n",
      "3.507907048560459e-06\n",
      "5.914332292927681e-13\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "kn_estimator = KneserNeyProbabilityEstimator(storage)\n",
    "# Estimating perplexity\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(kn_estimator, test_sents[:5])))\n",
    "print(kn_estimator.prob('To be'.split()))\n",
    "print(kn_estimator.prob('To be or not to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Определение языка документа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Постановка задачи:**  \n",
    "Одна из задач, которая может быть решена при помощи языковых моделей $-$ **определение языка документа**. Реализуйте два классификатора для определения языка документа:\n",
    "1. Наивный классификатор, который будет учитывать частоты символов и выбирать язык текста по признаку: распределение частот символов \"наиболее похоже\" на распределение частот символов в выбранном языке.\n",
    "2. Классификатор на основе языковых моделей. Сами придумайте, как он должен работать.  \n",
    "_Подсказка_: лучше считать n-грамы не по словам, а по символам.\n",
    "\n",
    "---\n",
    "\n",
    "**Как представлены данные:**  \n",
    "Во всех текстовых файлах на каждой строчке записано отдельное предложение.\n",
    "1. В папке _data_ находятся две папки: _full_ и _plain_. В _full_ находятся тексты в той форме, что они были взяты из сети, в _plain_ находятся те же самые тексты, но с них сначала была снята диакритика, а затем русский и греческий тексты были транслитерованы в английский.\n",
    "2. В каждой из папок _full_ и _plain_ находятся папки _train_ и _test_.\n",
    "3. В _train_ находятся файлы с текстами с говорящими именами, например, _ru.txt_, _en.txt_.\n",
    "4. В _test_ находятся файлы _1.txt_, _2.txt_, $\\dots$ в которых хранятся тексты, язык которых нужно определить. В этой же папке находится файл _ans.csv_, в котором вы можете найти правильные ответы и проверить, насколько хорошо сработали Ваши алгоритмы.\n",
    "\n",
    "---\n",
    "\n",
    "**Что нужно сделать:**  \n",
    "Напишите два своих классификатора (которые описаны в постановке задачи) и получите максимально возможное accuracy на test-сете. Разрешается использовать только _train_ для обучения.\n",
    "\n",
    "---\n",
    "\n",
    "**В данном задании мы не предоставляем стартового кода!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом решении просто каждому языку сопоставляем частоты символов, а потом для каждого нового текста сравниваем частоту для него и частоты всех языков с помощью mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NaiveClassifier:\n",
    "    def __init__(self):\n",
    "        # chars frequences\n",
    "        self.__matcher = {}\n",
    "        self.__max_char = 1114112\n",
    "    \n",
    "    def add(self, words, lang):\n",
    "        chars = [0 for _ in range(self.__max_char)]\n",
    "        chars_number = 0\n",
    "        for word in words:\n",
    "            for char in word:\n",
    "                chars[ord(char)] = chars[ord(char)] + 1\n",
    "                chars_number = chars_number + 1\n",
    "        for i in range(self.__max_char):\n",
    "            chars[i] = chars[i] / chars_number\n",
    "        self.__matcher[lang] = np.array(chars)\n",
    "    \n",
    "    def evaluate(self, sents):\n",
    "        chars = [0 for _ in range(self.__max_char)]\n",
    "        chars_number = 0\n",
    "        for word in words:\n",
    "            for char in word:\n",
    "                chars[ord(char)] = chars[ord(char)] + 1\n",
    "                chars_number = chars_number + 1\n",
    "        for i in range(self.__max_char):\n",
    "            chars[i] = chars[i] / chars_number\n",
    "        min_mse = 10000000\n",
    "        chars = np.array(chars)\n",
    "        final_lang = \"\"\n",
    "        for lang in self.__matcher.keys():\n",
    "            mse = ((chars - self.__matcher[lang]) ** 2).mean()\n",
    "            if mse < min_mse:\n",
    "                min_mse = mse\n",
    "                final_lang = lang\n",
    "        return final_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "naive_classifier = NaiveClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сопостовляем языкам частоты символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filename in os.listdir(\"full/train/\"):\n",
    "    if filename.endswith(\".txt\"): \n",
    "        file = open(\"full/train/\" + filename, 'r')\n",
    "        lang = filename[:-4]\n",
    "        words = re.split('(\\W+)', file.read()) \n",
    "        # there is empty file eo.txt\n",
    "        if len(words) != 1:\n",
    "            naive_classifier.add(words, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравниваем полученные для данного файла частоты с частотами для языков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer = {}\n",
    "for filename in os.listdir(\"full/test/\"):\n",
    "    if filename.endswith(\".txt\"): \n",
    "        file = open(\"full/test/\" + filename, 'r')\n",
    "        words = re.split('(\\W+)', file.read()) \n",
    "        lang = naive_classifier.evaluate(words)\n",
    "        answer[filename[:-4]] = lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"full/test/ans.csv\", header=None)\n",
    "real_answer = {}\n",
    "for i in range(data[0].size):\n",
    "    real_answer[str(i + 1)] = data[1][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "correct_answers = 0\n",
    "for i in range(data[0].size):\n",
    "    if real_answer[str(i + 1)] == answer[str(i + 1)]:\n",
    "        correct_answers = correct_answers + 1\n",
    "print(\"Accuracy:\", correct_answers / data[0].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давайте о языковой модели. Как было упомянуто на лекции надо взять аргмакс по языку p(text|lang). То есть это значит, что для каждого языка мы можем построить его языковую модель, а потом на тесте посчитать вероятность тестового текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Причем будем оценивать весь текст целиком. Так как он является нашей единицей измерения. И использовать интерполяционное сглаживание + трехграмной моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NgramClassifier:\n",
    "    def __init__(self):\n",
    "        # smoothing\n",
    "        self.__matcher = {}\n",
    "    \n",
    "    def add(self, text, lang):\n",
    "        storage = NGramStorage([list(text)], 3)\n",
    "        simple_estimator = StraightforwardProbabilityEstimator(\n",
    "            storage)\n",
    "        self.__matcher[lang] = InterpolationProbabilityEstimator(\n",
    "            simple_estimator, np.array([0.2, 0.2, 0.6]))\n",
    "        print(\"Estimator for\", lang, \"is ready\")\n",
    "    \n",
    "    def evaluate(self, text):\n",
    "        final_lang = \"\"\n",
    "        max_prob = 0.\n",
    "        for lang in self.__matcher.keys():\n",
    "            prob = self.__matcher[lang].prob(list(text))\n",
    "            if prob > max_prob:\n",
    "                max_prob = prob\n",
    "                final_lang = lang\n",
    "        return final_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngram_classifier = NgramClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем сглаживания для каждого языка по всему тексту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimator for fr is ready\n",
      "Estimator for fi is ready\n",
      "Estimator for pt is ready\n",
      "Estimator for ca is ready\n",
      "Estimator for nl is ready\n",
      "Estimator for it is ready\n",
      "Estimator for hu is ready\n",
      "Estimator for es is ready\n",
      "Estimator for en is ready\n",
      "Estimator for ru is ready\n",
      "Estimator for pl is ready\n",
      "Estimator for sv is ready\n",
      "Estimator for el is ready\n",
      "Estimator for de is ready\n",
      "Estimator for no is ready\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(\"full/train/\"):\n",
    "    if filename.endswith(\".txt\"): \n",
    "        file = open(\"full/train/\" + filename, 'r')\n",
    "        lang = filename[:-4]\n",
    "        # there is empty file eo.txt\n",
    "        text = file.read()\n",
    "        if len(text) != 0:\n",
    "            ngram_classifier.add(text, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем вероятность того, что какой-то текст принадлежит конкретному языку (то есть по сути просто вероятность того, что он сгенерирован из соответствующего теста)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer = {}\n",
    "for filename in os.listdir(\"full/test/\"):\n",
    "    if filename.endswith(\".txt\"): \n",
    "        file = open(\"full/test/\" + filename, 'r')\n",
    "        lang = ngram_classifier.evaluate(file.read())\n",
    "        answer[filename[:-4]] = lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.008333333333333333\n"
     ]
    }
   ],
   "source": [
    "correct_answers = 0\n",
    "for i in range(data[0].size):\n",
    "    if real_answer[str(i + 1)] == answer[str(i + 1)]:\n",
    "        correct_answers = correct_answers + 1\n",
    "print(\"Accuracy:\", correct_answers / data[0].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опять исполняется долго, но, код не ботает и не тормозит совсем. Если будет возможность выписать что он в итоге вернул после, то я сделаю это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
