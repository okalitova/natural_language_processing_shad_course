{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Контекстно-свободные грамматики  \n",
    "Курс NLP, семинар 11.  \n",
    "Осень 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подпись: Калитова Ольга Сергеевна АД(?) 4(?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://i.imgur.com/XLREeKo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Немного теории\n",
    "\n",
    "*Формальная грамматика* (определение с лекции):\n",
    " - конечное множество нетерминалов $P$;\n",
    " - конечное множество терминалов $\\Sigma$;\n",
    " - конечное множество продукций $P$, каждая из которых имеет вид\n",
    " \n",
    "$$(\\Sigma \\cup N)^∗ N (\\Sigma \\cup N)^∗ \\rightarrow (\\Sigma \\cup N)^∗$$\n",
    " - начальный нетерминал $S$.\n",
    " \n",
    "*Контекстно-свободная грамматика* имеет правила вида $A \\rightarrow \\beta, \\beta \\in (N \\cup \\Sigma)^*$.\n",
    "\n",
    "\n",
    "Контекстно-свободная является грамматикой в *нормальной форме Хомского*, если содержит только правила вида: \n",
    " - $A \\rightarrow B C$\n",
    " - $A \\rightarrow a$\n",
    " - $S \\rightarrow \\varepsilon$\n",
    "\n",
    "где $a$ $-$ терминал, $A, B, C$ $-$ нетерминалы, $S$ $-$ начальный нетерминал не содержащийся в правых частях правил, $\\varepsilon$ $-$ пустая строка.\n",
    "\n",
    "Как привести грамматику к нормальной форме Хомского можно прочитать [здесь](http://math.stackexchange.com/questions/296243/converting-to-chomsky-normal-form) или [здесь](http://neerc.ifmo.ru/wiki/index.php?title=Нормальная_форма_Хомского#.D0.9F.D1.80.D0.B8.D0.B2.D0.B5.D0.B4.D0.B5.D0.BD.D0.B8.D0.B5_.D0.B3.D1.80.D0.B0.D0.BC.D0.BC.D0.B0.D1.82.D0.B8.D0.BA.D0.B8_.D0.BA_.D0.BD.D0.BE.D1.80.D0.BC.D0.B0.D0.BB.D1.8C.D0.BD.D0.BE.D0.B9_.D1.84.D0.BE.D1.80.D0.BC.D0.B5_.D0.A5.D0.BE.D0.BC.D1.81.D0.BA.D0.BE.D0.B3.D0.BE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chomsky Normal Form \n",
    "Приведите грамматику к нормальной форме Хомского (и выпишите итоговую <font color='red'>внутри ipython ноутбука</font>):\n",
    "\n",
    "- $S \\rightarrow NP ~~ VP$\n",
    "- $NP \\rightarrow DET ~~ ADJ ~~ N \\mid NN$\n",
    "- $VP \\rightarrow V ~~ NP \\mid VP ~~ PP \\mid V$\n",
    "- $DET \\rightarrow a$\n",
    "- $ADJ \\rightarrow tasty \\mid ADV ~~ ADJ \\mid \\epsilon$\n",
    "- $ADV \\rightarrow very$\n",
    "- $N \\rightarrow fish \\mid fork \\mid dog \\mid boy$\n",
    "- $NN \\rightarrow Mary \\mid John$\n",
    "- $V \\rightarrow eats$\n",
    "- $PP \\rightarrow P ~~ NP \\mid \\epsilon$\n",
    "- $P \\rightarrow with$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CYK Parser\n",
    "\n",
    "Реализуйте синтаксический парсер, работающий по методу [**CYK**](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9A%D0%BE%D0%BA%D0%B0_%E2%80%94_%D0%AF%D0%BD%D0%B3%D0%B5%D1%80%D0%B0_%E2%80%94_%D0%9A%D0%B0%D1%81%D0%B0%D0%BC%D0%B8) и выполняющий функцию проверки принадлежности строки грамматике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "class CYKParser:\n",
    "    def __init__(self, rules):\n",
    "        \"\"\"\n",
    "            `rules` - your grammar\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "        self._rules = rules\n",
    "        ### END OF YOUR CODE\n",
    "    \n",
    "    ### SOME ADDITION FUNCTIONS IF YOU NEED IT\n",
    "    ###\n",
    "    ### END YOUR ADDITIONAL FUNCTIONS\n",
    "\n",
    "    def parse(self, in_tokens):\n",
    "        \"\"\"\n",
    "            `in_tokens` - input sentence\n",
    "            return True in case of sentence can be parsed, False otherwise\n",
    "        \"\"\"\n",
    "        c = [[[] for i in range(len(in_tokens))] for j in range(len(in_tokens)) ]\n",
    "        ### YOUR CODE HERE\n",
    "        for j in range(len(in_tokens)):\n",
    "            for key, values in self._rules.items():\n",
    "                if in_tokens[j] in values:\n",
    "                    c[j][j].append(key)\n",
    "            for i in range(j - 1, -1, -1):\n",
    "                for k in range(i + 1, j + 1):\n",
    "                    for key, values in self._rules.items():\n",
    "                        for value in values:\n",
    "                            BC = value.split(\" \")\n",
    "                            if len(BC) != 2:\n",
    "                                continue\n",
    "                            [B, C] = BC\n",
    "                            if B in c[i][k - 1] and C in c[k][j]:\n",
    "                                c[i][j].append(key)\n",
    "        if 'S' in c[0][len(in_tokens) - 1]:\n",
    "            return True\n",
    "        return False\n",
    "            \n",
    "        ### END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введите сюда полученную грамматику из первого пункта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RULES = {\n",
    "    'S': ['NP VP'],\n",
    "    'NP': ['DET ADJN', 'DET N', 'Mary', 'John'],\n",
    "    'VP': ['V NP', 'VP PP', 'eats'],\n",
    "    'DET': ['a'],\n",
    "    'ADJ': ['tasty', 'ADV ADJ', 'very'],\n",
    "    'ADV': ['very'],\n",
    "    'N': ['fish', 'fork', 'dog', 'boy'],\n",
    "    'NN': ['Mary', 'John'],\n",
    "    'V': ['eats'],\n",
    "    'PP': ['P NP'],\n",
    "    'P': ['with'],\n",
    "    'ADJN': ['ADJ N']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время проверить нашу грамматику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positve examples:\n",
      "-------------------------------------------------------------\n",
      "OK! Mary eats a fish\n",
      "OK! John eats a very very very tasty fish with a fork\n",
      "OK! a dog eats a boy\n",
      "OK! Mary eats John with a fork\n",
      "OK! John eats a fork\n",
      "OK! a very fish eats Mary\n",
      "*************************************************************\n",
      "Negative examples:\n",
      "-------------------------------------------------------------\n",
      "OK! John\n",
      "OK! Mary eats a eats\n",
      "OK! boy eats dog\n",
      "OK! John eats a very very very tasty fish with fork\n",
      "OK! a Mary fork\n",
      "OK! eats\n",
      "OK! a\n",
      "*************************************************************\n"
     ]
    }
   ],
   "source": [
    "correct_sentences = [\n",
    "    'Mary eats a fish',\n",
    "    'John eats a very very very tasty fish with a fork',\n",
    "    'a dog eats a boy',\n",
    "    'Mary eats John with a fork',\n",
    "    'John eats a fork',\n",
    "    'a very fish eats Mary'\n",
    "]\n",
    "\n",
    "not_correct_sentences = [\n",
    "    'John',\n",
    "    'Mary eats a eats',\n",
    "    'boy eats dog',\n",
    "    'John eats a very very very tasty fish with fork',\n",
    "    'a Mary fork',\n",
    "    'eats',\n",
    "    'a'\n",
    "]\n",
    "\n",
    "parser = CYKParser(RULES)\n",
    "print('Positve examples:')\n",
    "print('-------------------------------------------------------------')\n",
    "for sentence in correct_sentences:\n",
    "    if parser.parse(sentence.split()):\n",
    "        print('OK!', sentence)\n",
    "    else:\n",
    "        print('ERROR!', sentence)\n",
    "print('*************************************************************')\n",
    "print('Negative examples:')  \n",
    "print('-------------------------------------------------------------')\n",
    "for sentence in not_correct_sentences:\n",
    "    if not parser.parse(sentence.split()):\n",
    "        print('OK!', sentence)\n",
    "    else:\n",
    "        print('ERROR!', sentence)\n",
    "print('*************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extended CYK Parser \n",
    "\n",
    "Модифицируйте парсер так, чтобы он возвращал цепочку правил, составляющих разбор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections import defaultdict\n",
    "\n",
    "class CYKParser:\n",
    "    def __init__(self, rules):\n",
    "        \"\"\"\n",
    "            `rules` - your grammar\n",
    "        \"\"\"\n",
    "        ### YOUR CODE HERE\n",
    "        self._rules = rules\n",
    "        ### END OF YOUR CODE\n",
    "    \n",
    "    ### SOME ADDITION FUNCTIONS IF YOU NEED IT\n",
    "    ###\n",
    "    ### END YOUR ADDITIONAL FUNCTIONS\n",
    "    \n",
    "    def dfs(self, key, i, j):\n",
    "        if i == j:\n",
    "            return [key + ' -> ' + self._path[i][j][key]]\n",
    "        B, C, i, k, j = self._path[i][j][key]\n",
    "#         print(B, C, i, k, j)\n",
    "#         print(self.dfs(B, i, k -1) + [key + '->' + B + ',' + C] + self.dfs(C, k, j))\n",
    "        return [key + ' -> ' + B + ' ' + C] + self.dfs(B, i, k -1) + self.dfs(C, k, j)\n",
    "\n",
    "    def parse(self, in_tokens):\n",
    "        \"\"\"\n",
    "            `in_tokens` - input sentence\n",
    "            return True in case of sentence can be parsed, False otherwise\n",
    "        \"\"\"\n",
    "        c = [[[] for i in range(len(in_tokens))] for j in range(len(in_tokens)) ]\n",
    "        self._path = [[defaultdict(int) for i in range(len(in_tokens))] for j in range(len(in_tokens)) ]\n",
    "        ### YOUR CODE HERE\n",
    "        for j in range(len(in_tokens)):\n",
    "            for key, values in self._rules.items():\n",
    "                if in_tokens[j] in values:\n",
    "                    c[j][j].append(key)\n",
    "                    self._path[j][j][key] = in_tokens[j]\n",
    "            for i in range(j - 1, -1, -1):\n",
    "                for k in range(i + 1, j + 1):\n",
    "                    for key, values in self._rules.items():\n",
    "                        for value in values:\n",
    "                            BC = value.split(\" \")\n",
    "                            if len(BC) != 2:\n",
    "                                continue\n",
    "                            [B, C] = BC\n",
    "                            if B in c[i][k - 1] and C in c[k][j]:\n",
    "                                c[i][j].append(key)\n",
    "                                self._path[i][j][key] = (B, C, i, k, j)\n",
    "        if 'S' in c[0][len(in_tokens) - 1]:\n",
    "             return [self.dfs('S', 0, len(in_tokens) - 1)]\n",
    "        return []\n",
    "            \n",
    "        ### END OF YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S -> NP VP\n",
      "NP -> Mary\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> fish\n",
      "\n",
      "S -> NP VP\n",
      "NP -> John\n",
      "VP -> VP PP\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> DET ADJN\n",
      "DET -> a\n",
      "ADJN -> ADJ N\n",
      "ADJ -> ADV ADJ\n",
      "ADV -> very\n",
      "ADJ -> ADV ADJ\n",
      "ADV -> very\n",
      "ADJ -> ADV ADJ\n",
      "ADV -> very\n",
      "ADJ -> tasty\n",
      "N -> fish\n",
      "PP -> P NP\n",
      "P -> with\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> fork\n",
      "\n",
      "S -> NP VP\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> dog\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> boy\n",
      "\n",
      "S -> NP VP\n",
      "NP -> Mary\n",
      "VP -> VP PP\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> John\n",
      "PP -> P NP\n",
      "P -> with\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> fork\n",
      "\n",
      "S -> NP VP\n",
      "NP -> John\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> DET N\n",
      "DET -> a\n",
      "N -> fork\n",
      "\n",
      "S -> NP VP\n",
      "NP -> DET ADJN\n",
      "DET -> a\n",
      "ADJN -> ADJ N\n",
      "ADJ -> very\n",
      "N -> fish\n",
      "VP -> V NP\n",
      "V -> eats\n",
      "NP -> Mary\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in correct_sentences:\n",
    "#     print(CYKParser(RULES).parse(sent.split()))\n",
    "    for chain in CYKParser(RULES).parse(sent.split()):\n",
    "        for rule in chain:\n",
    "            print(rule)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вместо заключения \n",
    "\n",
    "Вспомним про nltk и Earley парсер. Грамматики тут задаются следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S -> NP VP\n",
    "    NP -> Det ADJ N | NN\n",
    "    VP -> V NP | VP PP | V\n",
    "    Det -> 'a'\n",
    "    ADJ -> 'tasty' | ADV ADJ | \n",
    "    ADV -> 'very'\n",
    "    N -> 'fish' | 'fork' | 'dog' | 'boy'\n",
    "    NN -> 'Mary' | 'John'\n",
    "    V -> 'eats'\n",
    "    PP -> P NP | \n",
    "    P -> 'with'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим парсер и применим к предложению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = nltk.EarleyChartParser(grammar)\n",
    "trees = list(parser.parse('a very fish eats Mary'.split()))\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы увидеть сам разбор, достаточно установить параметр *trace* у парсера (по умолчанию trace=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = nltk.EarleyChartParser(grammar, trace=1)\n",
    "trees = parser.parse('Mary eats a fish'.split())\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = nltk.EarleyChartParser(grammar, trace=2)\n",
    "trees = parser.parse('John eats a very very very tasty fish with a fork'.split())\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
