{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vowpal Wabbit в NLP\n",
    "Автоматическая обработка текстов - 2017, семинар 4.\n",
    "\n",
    "В этом семинаре мы познакомимся с библиотекой Vowpal Wabbit и решим с его помощью задачу многоклассовой классификации на больших данных. \n",
    "Данные скачайте [здесь](https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/data) или запустите следующие две ячейки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! wget https://www.dropbox.com/s/r0q0p0uprhcp8bb/train-sample.zip\n",
    "# ! unzip train-sample.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ! wget https://www.dropbox.com/s/50vw2gsglc91f6o/train.zip\n",
    "# ! unzip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы на семинаре не тратить время на обработку и обучение моделей на всех данных, предлагается использовать только небольшую подвыборку (`train-sample.csv`). Но сдавать ноутбук все равно необходимо с результатами на **всех** данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BodyMarkdown': \"I'm new to C#, and I want to use a trackbar for the forms opacity\\nThis is my code\\n\\n    decimal trans = trackBar1.Value / 5000\\n    this.Opacity = trans\\n\\nWhen I try to build it, I get this error\\n\\n**Cannot implicitly convert type 'decimal' to 'double**\\n\\nI tried making trans a double, but then the control doesn't work. This code worked fine for me in VB.NET. Any suggestions?\",\n",
       " 'OpenStatus': 'open',\n",
       " 'OwnerCreationDate': '07/31/2008 21:33:24',\n",
       " 'OwnerUndeletedAnswerCountAtPostTime': '0',\n",
       " 'OwnerUserId': '8',\n",
       " 'PostClosedDate': '',\n",
       " 'PostCreationDate': '07/31/2008 21:42:52',\n",
       " 'PostId': '4',\n",
       " 'ReputationAtPostCreation': '1',\n",
       " 'Tag1': 'c#',\n",
       " 'Tag2': '',\n",
       " 'Tag3': '',\n",
       " 'Tag4': '',\n",
       " 'Tag5': '',\n",
       " 'Title': 'Decimal vs Double?'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "INPUT_DATA = 'train.csv'\n",
    "# INPUT_DATA = 'train-sample.csv'\n",
    "\n",
    "reader = csv.DictReader(open(INPUT_DATA))\n",
    "dict(next(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект выборки соответствует некоторому посту на Stack Overflow. Требуется построить модель, определяющую статус поста. Подробнее про задачу и формат данных можно прочитать на [странице соревнования](https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow).\n",
    "\n",
    "Перед обучением модели из Vowpal Wabbit данные следует сохранить в специальный формат: <br>\n",
    "`label |namespace1 feature1:value1 feature2 feature3:value3 |namespace2 ...` <br>\n",
    "Записи `feature` и `feature:1.0` эквивалентны. Выделение признаков в смысловые подгруппы (namespaces) позволяет создавать взаимодействия между ними. Подробнее про формат входных данных можно прочитать [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format).\n",
    "\n",
    "Ниже реализована функция, которая извлекает признаки с помощью подаваемого на вход экстрактора, разбивает данные на трейн и тест и записывает их на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "STATUSES = ['not a real question', 'not constructive', 'off topic', 'open', 'too localized']\n",
    "STATUS_DICT = {status: i+1 for i, status in enumerate(STATUSES)}\n",
    "\n",
    "def data2vw(features_extractor, train_output='train', test_output='test', ytest_output='ytest'):\n",
    "    reader = csv.DictReader(open(INPUT_DATA, encoding='utf-8'))\n",
    "    writer_train = open(train_output, 'w')\n",
    "    writer_test = open(test_output, 'w')\n",
    "    writer_ytest = open(ytest_output, 'w')\n",
    "    \n",
    "    for row in tqdm_notebook(reader):\n",
    "        label = STATUS_DICT[row['OpenStatus']]\n",
    "        features = features_extractor(row)\n",
    "        output_line = str(label) + \" \"\n",
    "        for namespace, words in features.items():\n",
    "            output_line += \"|\" + namespace + \" \"\n",
    "            output_line += words + \" \"\n",
    "        output_line += \"\\n\"\n",
    "        if int(row['PostId']) % 2 == 0:\n",
    "            writer_train.write(output_line)\n",
    "        else:\n",
    "            writer_test.write(output_line)\n",
    "            writer_ytest.write('%s\\n' % label)\n",
    "            \n",
    "    writer_train.close()\n",
    "    writer_test.close()\n",
    "    writer_ytest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с простейшей модели. В качестве признаков возьмите заголовки и очистите их: приведите символы к нижнему регистру, удалите пунктуацию. Также приветствуется использование стеммеров/лемматизаторов, однако учтите, что они могут сильно замедлить скорость обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 |t decimal vs double \n",
      "4 |t percentage width child in absolutely positioned parent doesnt work in ie7 \n",
      "4 |t tools for porting j code to c \n",
      "4 |t throw error in mysql trigger \n",
      "4 |t whats the difference between mathfloor and mathtruncate \n"
     ]
    }
   ],
   "source": [
    "def extract_title(row):\n",
    "    title = row['Title']\n",
    "    title = title.lower()\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    title = title.translate(translator)\n",
    "    title = re.split('\\s', title)\n",
    "    return ' '.join(title)\n",
    "\n",
    "data2vw(lambda row: {'t': extract_title(row)})\n",
    "\n",
    "! head -n 5 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим `vw` модель. Параметр `-d` отвечает за путь к обучающей выборке, `-f` – за путь к модели, `--oaa` – за режим мультиклассовой классификации `one-against-all`. Подробное описание всех параметров можно найти [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Command-line-arguments) или вызвать `vw --help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        4        1        4\n",
      "0.500000 0.000000            2            2.0        4        4       12\n",
      "0.250000 0.000000            4            4.0        4        4        6\n",
      "0.125000 0.000000            8            8.0        4        4        7\n",
      "0.062500 0.000000           16           16.0        4        4        4\n",
      "0.062500 0.062500           32           32.0        4        4        9\n",
      "0.046875 0.031250           64           64.0        4        4        5\n",
      "0.062500 0.078125          128          128.0        4        4       11\n",
      "0.089844 0.117188          256          256.0        4        4        8\n",
      "0.070312 0.050781          512          512.0        4        4        5\n",
      "0.066406 0.062500         1024         1024.0        4        4        8\n",
      "0.063965 0.061523         2048         2048.0        4        4        7\n",
      "0.056641 0.049316         4096         4096.0        4        4       11\n",
      "0.053467 0.050293         8192         8192.0        4        4        6\n",
      "0.043579 0.033691        16384        16384.0        4        4       14\n",
      "0.033539 0.023499        32768        32768.0        4        4       15\n",
      "0.023651 0.013763        65536        65536.0        4        4        7\n",
      "0.016586 0.009521       131072       131072.0        4        4       12\n",
      "0.011845 0.007103       262144       262144.0        4        4       14\n",
      "0.011805 0.011765       524288       524288.0        4        4       11\n",
      "0.016265 0.020725      1048576      1048576.0        4        4       11\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1685253\n",
      "passes used = 1\n",
      "weighted example sum = 1685253.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.020987\n",
      "total feature number = 15392956\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим модель к тестовой выборке и сохраним предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "raw predictions = pred\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        4        4        9\n",
      "0.000000 0.000000            2            2.0        4        4        7\n",
      "0.000000 0.000000            4            4.0        4        4        8\n",
      "0.125000 0.250000            8            8.0        4        4        6\n",
      "0.125000 0.125000           16           16.0        4        4        7\n",
      "0.156250 0.187500           32           32.0        4        4       10\n",
      "0.093750 0.031250           64           64.0        4        4        8\n",
      "0.117188 0.140625          128          128.0        4        4        8\n",
      "0.121094 0.125000          256          256.0        4        4       16\n",
      "0.105469 0.089844          512          512.0        4        4       11\n",
      "0.094727 0.083984         1024         1024.0        4        4       10\n",
      "0.082520 0.070312         2048         2048.0        4        4       14\n",
      "0.066162 0.049805         4096         4096.0        4        4        7\n",
      "0.062134 0.058105         8192         8192.0        4        4        4\n",
      "0.050110 0.038086        16384        16384.0        4        4        6\n",
      "0.040314 0.030518        32768        32768.0        4        4       14\n",
      "0.029846 0.019379        65536        65536.0        4        4        8\n",
      "0.021492 0.013138       131072       131072.0        4        4       10\n",
      "0.015938 0.010384       262144       262144.0        4        4        6\n",
      "0.015015 0.014091       524288       524288.0        4        4        5\n",
      "0.018265 0.021515      1048576      1048576.0        4        4       11\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1685275\n",
      "passes used = 1\n",
      "weighted example sum = 1685275.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.022152\n",
      "total feature number = 15397655\n"
     ]
    }
   ],
   "source": [
    "! vw -i model -t test -r pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:-4.28213 2:-6.08996 3:-4.31059 4:2.40051 5:-6.81148\r\n",
      "1:-7.59211 2:-7.83689 3:-9.37969 4:5.67713 5:-8.07567\r\n",
      "1:-5.24459 2:-6.75469 3:-7.29165 4:3.59159 5:-7.48763\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 3 pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию, которая вычисляет `logloss` и `accuracy`, не загружая вектора в память. Используйте `softmax`, чтобы получить вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_scores(ytest_input='ytest', pred_input='pred'):\n",
    "    n, error, loss = 0, 0, 0\n",
    "    reader_ytest = open(ytest_input, 'r')\n",
    "    reader_pred = open(pred_input, 'r')\n",
    "    \n",
    "    for label, pred in zip(reader_ytest, reader_pred):\n",
    "        probs = []\n",
    "        classes = pred[:-1].split(' ')\n",
    "        for cl in classes:\n",
    "            pred_label, pr_label = cl.split(':')\n",
    "            pr_label = float(pr_label)\n",
    "            probs.append(math.exp(pr_label))\n",
    "        probs = np.array(probs) / np.array(probs).sum()\n",
    "        \n",
    "        max_prob_arg = np.argmax(probs) + 1\n",
    "        max_prob = np.max(probs)\n",
    "        \n",
    "        #accuracy\n",
    "        if int(label) != max_prob_arg:\n",
    "            error = error + 1\n",
    "        n = n + 1\n",
    "        \n",
    "        #logloss\n",
    "        loss = loss + math.log(probs[int(label) - 1])\n",
    "        \n",
    "    reader_ytest.close()\n",
    "    reader_pred.close()\n",
    "    return - loss / n, 1 - float(error) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.14763\n",
      "accuracy = 0.97785\n"
     ]
    }
   ],
   "source": [
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На оригинальных данных `logloss` должен быть меньше `0.20`, `accuracy` больше `0.95`. Если это не так, то скорее всего у вас ошибка.\n",
    "\n",
    "Теперь попробуем улучшить модель, добавив новые признаки, порождаемые словами. В `vowpal wabbit` есть возможность делать это прямо на лету. Воспользуйтесь параметрами `affix`, `ngram`, `skips`.\n",
    "\n",
    "Далее везде при подборе параметров ориентируйтесь на улучшение `logloss`. Используйте `--quiet` или `-P`, чтобы избавиться от длинных выводов при обучении и применении моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.14177\n",
      "accuracy = 0.97814\n",
      "logloss  = 0.14537\n",
      "accuracy = 0.97799\n",
      "logloss  = 0.14848\n",
      "accuracy = 0.97780\n",
      "logloss  = 0.15056\n",
      "accuracy = 0.97762\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --affix -2t --loss_function logistic --oaa 5 -f model 2> trash\n",
    "! vw -i model -t test -r pred 2> trash\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())\n",
    "! vw -d train --affix -3t --loss_function logistic --oaa 5 -f model 2> trash\n",
    "! vw -i model -t test -r pred 2> trash\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())\n",
    "! vw -d train --affix -4t --loss_function logistic --oaa 5 -f model 2> trash\n",
    "! vw -i model -t test -r pred 2> trash\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())\n",
    "! vw -d train --affix -5t --loss_function logistic --oaa 5 -f model 2> trash\n",
    "! vw -i model -t test -r pred 2> trash\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеет смысл рассмотреть суффиксы длины 2, но мы не будем, так как изменение совсем незначительное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.13947\n",
      "accuracy = 0.97818\n",
      "logloss  = 0.14094\n",
      "accuracy = 0.97817\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    ! vw -d train --affix \"$i\"t --loss_function logistic --oaa 5 -f model 2> trash\n",
    "    ! vw -i model -t test -r pred 2> trash\n",
    "    print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, префиксы чуть более полезны, но тоже не то что бы оч сильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.17199\n",
      "accuracy = 0.97599\n",
      "logloss  = 0.18143\n",
      "accuracy = 0.97571\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 4):\n",
    "    ! vw -d train --ngram t\"$i\" --loss_function logistic --oaa 5 -f model 2> trash\n",
    "    ! vw -i model -t test -r pred 2> trash\n",
    "    print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мда, в данном случае нграммы - зло."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто качество `vw` модели получается учушить увеличением числа проходов по обучающей выборке (параметр `--passes`) и увеличением числа бит хэш-функции для уменьшения числа коллизий признаков (параметр `-b`). Подробнее про то, где в `vowpal wabbit` используется хэш-функция, можно прочитать [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Feature-Hashing-and-Extraction). Как меняется качество при изменении этих параметров? Верно ли, что при увеличении значений параметров `--passes` и `-b` качество всегда не убывает и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logloss = [0 for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.14763\n",
      "accuracy = 0.97785\n",
      "logloss  = 0.14696\n",
      "accuracy = 0.97794\n",
      "logloss  = 0.14722\n",
      "accuracy = 0.97798\n",
      "logloss  = 0.14845\n",
      "accuracy = 0.97792\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    ! vw -d train --passes \"$i\" --cache_file cache --loss_function logistic --oaa 5 -f model 2> trash\n",
    "    ! vw -i model -t test -r pred 2> trash\n",
    "    ll, acc = get_scores()\n",
    "    logloss[i] = ll\n",
    "    print('logloss  = %.5f\\naccuracy = %.5f' % (ll, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет смысла пытаться делать больше passes. Потому что видно, что если 2 прохода имеют какой-то смысл, то не больше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идеи, почему не улучшает:\n",
    "    1. переобучение?\n",
    "    2. порядок прохода не меняется, тем самым мы по сути повторяем, что уже было."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем поизучать коллизии признаков, когда их хоть немного больше. Например, добавим префиксы длины 1. Единственное, что что-то хоть сколько-то существенно улучшало."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.13925\n",
      "accuracy = 0.97817\n",
      "logloss  = 0.13934\n",
      "accuracy = 0.97816\n",
      "logloss  = 0.13957\n",
      "accuracy = 0.97815\n"
     ]
    }
   ],
   "source": [
    "for i in range(19, 22):\n",
    "    ! vw -d train --affix 1t -b \"$i\" --loss_function logistic --oaa 5 -f model 2> trash\n",
    "    ! vw -i model -t test -r pred 2> trash\n",
    "    print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Только при малом увеличении происходит маленькое улучшение. Я думаю, что тут разгадка ясна - коллизий наверное почти и нет. И так как зависимость тут экспоненуциальная, то 1 байт решает проблему."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь интерес представляет то, какие признаки оказались наиболее важными для модели. Для этого сначала переведем модель в читаемый формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 8.4.0\r\n",
      "Id \r\n",
      "Min label:-50\r\n",
      "Max label:50\r\n",
      "bits:21\r\n",
      "lda:0\r\n",
      "0 ngram:\r\n",
      "0 skip:\r\n",
      "options: --affix 1t --oaa 5\r\n",
      "Checksum: 1358628434\r\n",
      ":0\r\n",
      "Constant:928480:-2.87754\r\n",
      "Constant[1]:928481:-3.50371\r\n",
      "Constant[2]:928482:-3.2816\r\n",
      "Constant[3]:928483:2.32285\r\n",
      "Constant[4]:928484:-3.60427\r\n",
      "affix^t+1=0:650976:0.0727394\r\n",
      "affix^t+1=0[1]:650977:-0.47062\r\n",
      "affix^t+1=0[2]:650978:-0.342807\r\n",
      "affix^t+1=0[3]:650979:0.0704274\r\n",
      "affix^t+1=0[4]:650980:-0.322214\r\n",
      "affix^t+1=1:256320:0.684885\r\n",
      "affix^t+1=1[1]:256321:-0.0287196\r\n",
      "affix^t+1=1[2]:256322:0.736937\r\n",
      "affix^t+1=1[3]:256323:-0.423031\r\n",
      "affix^t+1=1[4]:256324:0.512856\r\n",
      "affix^t+1=2:1958816:0.477723\r\n",
      "affix^t+1=2[1]:1958817:0.0749873\r\n",
      "affix^t+1=2[2]:1958818:0.679425\r\n",
      "affix^t+1=2[3]:1958819:-0.365776\r\n"
     ]
    }
   ],
   "source": [
    "! vw -i model -t --invert_hash model.readable train --quiet\n",
    "! head -n 30 model.readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые несколько строк соответствуют информации о модели. Далее следуют строчки вида `feature[label]:hash:weight`. Выделите для каждого класса 10 признаков с наибольшими по модулю весами. Постарайтесь сделать ваш алгоритм прохода по файлу константным по памяти. Например, можно воспользоваться [кучей](https://docs.python.org/2/library/heapq.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм с константной памятью:\n",
    "    храним кучу для класса, в которой <= 10 элементов. И это ровно те фичи, которым соответствуют максимальные веса. В корне будет минимальный вес из этих 10. Когда нам приходит новый вес, то мы смотрим больше ли он минимального из этих 10, если да - выкидываем минимальный и добавляем новую фичу в кучу, иначе оставляем все как есть. Тогда в итоговой куче будут лужать требуемые фичи (ну или веса, а фичи будем отдельно хранить в сете), не суть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heaps = [[] for _ in range(5)]\n",
    "valuable_features = [dict() for _ in range(5)]\n",
    "with open(\"model.readable\") as f:\n",
    "    index = 0\n",
    "    for row in f:\n",
    "        if index > 10:\n",
    "            feature, h, weight = row[:-1].split(':')\n",
    "            weight = float(weight)\n",
    "            feature_name = feature\n",
    "            label = 0\n",
    "            if feature[-1] == ']':  \n",
    "                feature_name = feature[:-3]\n",
    "                label = int(feature[-2])\n",
    "                \n",
    "            if len(heaps[label]) < 10:\n",
    "                heapq.heappush(heaps[label], weight)\n",
    "                valuable_features[label][feature_name] = weight\n",
    "            else:\n",
    "                if heaps[label][0] < weight:\n",
    "                    popped_w = heapq.heappop(heaps[label])\n",
    "                    # like this because there can be repeated weights\n",
    "                    for key, v in valuable_features[label].items():\n",
    "                        if v == popped_w:\n",
    "                            del valuable_features[label][key]\n",
    "                            break\n",
    "                    heapq.heappush(heaps[label], weight)\n",
    "                    valuable_features[label][feature_name] = weight\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'affix^t+1=s': 0.813683, 'affix^t+1=c': 0.786124, 't^columnvalue': 0.747511, 'affix^t+1=j': 0.711068, 't^cexecute': 0.786124, 'affix^t+1=w': 0.75395, 'affix^t+1=r': 0.83535, 'affix^t+1=e': 0.741504, 'affix^t+1=p': 0.892719, 'affix^t+1=d': 0.747511}, {'t^interview': 1.46757, 't^commonparameters': 2.03654, 't^best': 1.26148, 't^tricks': 1.07165, 't^twitt': 1.07165, 't^viewed': 1.26148, 't^quadword': 2.03654, 't^books': 2.03654, 't^acceptcontact': 1.46757, 't^learn': 1.11343}, {'t^cumsum': 1.10484, 't^controlscode': 1.02274, 't^ubuntu': 1.52074, 't^ninessix': 1.52074, 't^programmers': 0.783551, 't^latex': 1.02274, 't^seo': 0.85912, 't^uscanada': 0.989284, 't^ssh': 0.989284, 't^developer': 1.10484}, {'t^firing': 2.69258, 't^intstr': 2.67892, 't^uiwebview': 2.62544, 't^noninfrastructure': 2.77701, 't^jscrollpane': 2.77701, 't^unhandeled': 2.62544, 't^classpath': 2.8423, 't^javar': 2.8423, 't^yampaglut': 2.67892, 't^viewmodel': 2.67892}, {'affix^t+1=s': 0.718723, 'affix^t+1=c': 0.704568, 'affix^t+1=m': 0.572199, 'affix^t+1=l': 0.67334, 'affix^t+1=e': 0.70694, 'affix^t+1=p': 0.737395, 't^geddystringuuidx': 0.67334, 'affix^t+1=b': 0.686144, 'affix^t+1=r': 0.63065, 't^cexecute': 0.704568}]\n"
     ]
    }
   ],
   "source": [
    "print(valuable_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "забавно, можно сказать, что \n",
    "\n",
    "0 - что-то непонятное\n",
    "\n",
    "1 - интервью, советы\n",
    "\n",
    "2 - что-то... более системное? общее\n",
    "\n",
    "3 - как-то UI java в общем похоже на названия классов\n",
    "\n",
    "4 - опять что-то непонятное =(\n",
    "\n",
    "'not a real question',\n",
    "'not constructive',\n",
    "'off topic',\n",
    "'open',\n",
    "'too localized'\n",
    "    \n",
    "Похоже на правду! =)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Добавим признаки, извлеченные из текста поста (поле `BodyMarkdown`). В этом поле находится более подробная информация о вопросе, и часто туда помещают код, формулы и т.д. При удалении пунктуации мы потеряем много полезной информации, однако модель \"мешка слов\" на сырых данных может сильно раздуть признаковое пространство. В таких случаях работают с n-граммами на символах. <br>\n",
    "Будьте осторожны: символы \"`:`\" и \"`|`\" нельзя использовать в названиях признаков, поскольку они являются служебными для `vw`-формата. Замените эти символы на два других редко встречающихся в выборке (или вообще не встречающихся). Также не забудьте про \"`\\n`\". <br>\n",
    "Поскольку для каждого документа одна n-грамма может встретиться далеко не один раз, то будет экономнее записывать признаки в формате `[n-грамма]:[число вхождений]`.\n",
    "\n",
    "Также добавьте тэги (поля вид `TagN`). Придумайте и извлеките признаки из других полей. Только не используйте `PostClosedDate` – в нем содержится информация о таргете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ngrams(symbols, ngram=3):\n",
    "    n = len(symbols)\n",
    "    counter = defaultdict(int)\n",
    "    for i in range(0, n - ngram + 1):\n",
    "        new_ngram = \"\"\n",
    "        for j in range(ngram):\n",
    "            new_ngram = new_ngram + symbols[i + j]\n",
    "        counter[new_ngram] += 1\n",
    "        \n",
    "    ngrams_str = \"\"\n",
    "    for key, value in counter.items():\n",
    "        ngrams_str = ngrams_str + str(key) + \":\" + str(value) + \" \"\n",
    "    return ngrams_str\n",
    "\n",
    "def extract_ngram_body(row, ngram=3):\n",
    "    text = row['BodyMarkdown']\n",
    "    text = text.replace(\":\", \"ǂ\")\n",
    "    text = text.replace(\"|\", \"ɀ\")\n",
    "    text = text.replace(\"\\n\", \"ȸ\")\n",
    "    return get_ngrams(text, ngram)\n",
    "\n",
    "def extract_tags(row):\n",
    "    tags = \"\"\n",
    "    for i in range(5):\n",
    "        if len(row['Tag' + str(i + 1)]) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            tags = tags + row['Tag' + str(i + 1)] + \" \"\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим все вместе. Реализуйте экстрактор признаков, который выделяет каждую подгруппу в отдельный namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 |t decimal vs double |a c#  |b nd :1 oes:1 or :2 alu:1 in :1 'de:1  wa:1 uil:1 s o:1 al :1 e c:1 s a:1 rro:1 the:3 'm :1  fi:1 orȸ:1 ici:1 dou:2  ma:1 o ':1 tly:1 dec:2 onv:1 w t:1 r t:1  is:1 pac:2 ode:2 orm:1 *ȸȸ:1 tri:1 doe:1 ntr:1 k. :1 nsȸ:1 hen:2 m n:1 wor:2 s =:1 ert:1 y c:2 ȸȸW:1 00ȸ:1 Thi:2  ge:1  me:1 ans:3 ol :1 mal:2 o b:1 ld :1 ine:1 cim:2 . A:1  ty:1 tio:1 aci:2 VB.:1 tro:1 y =:1  bu:2 lue:1 itl:1 ed :2 B.N:1 sȸȸ:1 **C:1  tr:7 I g:1 ild:1 aki:1 kin:1 pli:1 I'm:1 opa:1 e w:1 ȸȸI:1 rol:1 bui:1 sn':1 ges:1 *Ca:1 is :4 ȸȸ*:1 NET:1  to:4 me :1 sug:1 est:1 wan:1 it,:1  my:1 ȸWh:1  I :3 rac:2 cod:2 ror:1 e f:2 his:4  su:1 , I:1  im:1   t:1 se :1 ked:1 **ȸ:1 he :2 lic:1 e**:1 000:1 tra:5 ȸȸ :1  a :2 s e:1  co:4 ann:1 y t:1 le,:1 ȸ**:1 to :4 cit:3 rt :1 t, :1 imp:1 thi:2 'do:1 d f:1  wo:2  = :2  do:2 't :1 o C:1 = t:2 try:1  Th:1 en :2  C#:1 ng :1 . T:1 ly :1 d m:1  'd:2 n't:1 #, :1 oub:2 500:1 d i:1    :4 r f:1 ran:3 ut :1 ET.:1 I t:2 n t:1 .Va:1 al':1 o u:1 eci:2 ant:1 ne :1 n I:1 ont:1 ver:1 yȸT:1 e ':1 a d:1 ckb:1 t t:4 for:3 deȸ:1 not:1 sti:1 r m:1 use:1 rms:1 ty :1  50:1 my :1  an:1  ne:1 .Op:1 rȸȸ:1 e i:1 gge:1 fin:1 t w:1 Opa:1 ar1:1 rk.:1 but:1 ȸI :1 Any:1 ot :1 ity:2 e /:1 et :1 rie:1 kBa:1 bar:1 n V:1 ry :1 de :1 ' t:1 ima:2   d:1 d I:1  op:1 eȸȸ:1 g t:1 get:1 C#,:1 ar :1 and:1 y s:1 ble:2 ue :1 e a:1  de:1 ied:1 / 5:1 s m:1 ȸTh:1 rke:1 a t:1 mpl:1 ew :1 is.:1 ack:2 t i:1  er:1 l d:1  in:1 ȸ  :2 le*:1  fo:3 ns :2 r1.:1 I w:1 l t:1  us:1 Can:1 ons:1 con:2 nve:1 Bar:1  VB:1 ckB:1 T. :1  th:5 0ȸ :1 ny :1 s c:1 s i:1 ugg:1 ion:1 e, :1 ubl:2 ing:1 ms :1 new:1 .NE:1 , a:1 l' :1 esn:1 kba:1 ype:1 Whe:1 mak:1 nt :1 pe :1 ns?:1 err:1  it:1 typ:1  / :1 s.O:1 tyȸ:1 ork:2 Val:1 , b:1  An:1 1.V:1 nno:1  \n"
     ]
    }
   ],
   "source": [
    "extractors_list = [\n",
    "    ('t', extract_title), \n",
    "    ('b', extract_ngram_body), \n",
    "    ('a', extract_tags)\n",
    "] # (namespace, extractor)\n",
    "\n",
    "\n",
    "def make_feature_extractor(extractors_list):\n",
    "    def feature_extractor(row):\n",
    "        d = dict()\n",
    "        for namespace, extractor in extractors_list:\n",
    "            d[namespace] = extractor(row)\n",
    "        return d\n",
    "    return feature_extractor\n",
    "    \n",
    "data2vw(make_feature_extractor(extractors_list))\n",
    "\n",
    "! head -n 1 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        4        1      390\n",
      "0.500000 0.000000            2            2.0        4        4      412\n",
      "0.250000 0.000000            4            4.0        4        4      135\n",
      "0.125000 0.000000            8            8.0        4        4      551\n",
      "0.062500 0.000000           16           16.0        4        4      447\n",
      "0.062500 0.062500           32           32.0        4        4      514\n",
      "0.046875 0.031250           64           64.0        4        4      798\n",
      "0.062500 0.078125          128          128.0        4        4      377\n",
      "0.089844 0.117188          256          256.0        4        4      419\n",
      "0.070312 0.050781          512          512.0        4        4      387\n",
      "0.066406 0.062500         1024         1024.0        4        4      311\n",
      "0.063965 0.061523         2048         2048.0        4        4      525\n",
      "0.056396 0.048828         4096         4096.0        4        4      350\n",
      "0.052856 0.049316         8192         8192.0        4        4      357\n",
      "0.043091 0.033325        16384        16384.0        4        4      531\n",
      "0.033203 0.023315        32768        32768.0        4        4      206\n",
      "0.023483 0.013763        65536        65536.0        4        4      485\n",
      "0.016495 0.009506       131072       131072.0        4        4      944\n",
      "0.011795 0.007095       262144       262144.0        4        4     1461\n",
      "0.011726 0.011658       524288       524288.0        4        4      294\n",
      "0.016262 0.020798      1048576      1048576.0        4        4     1343\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1685253\n",
      "passes used = 1\n",
      "weighted example sum = 1685253.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.021015\n",
      "total feature number = 978922398\n",
      "only testing\n",
      "raw predictions = pred\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        4        4      108\n",
      "0.000000 0.000000            2            2.0        4        4      737\n",
      "0.000000 0.000000            4            4.0        4        4     1572\n",
      "0.125000 0.250000            8            8.0        4        4      201\n",
      "0.125000 0.125000           16           16.0        4        4      161\n",
      "0.156250 0.187500           32           32.0        4        4      422\n",
      "0.093750 0.031250           64           64.0        4        4      377\n",
      "0.117188 0.140625          128          128.0        4        4      390\n",
      "0.128906 0.140625          256          256.0        4        4      345\n",
      "0.105469 0.082031          512          512.0        4        4      785\n",
      "0.093750 0.082031         1024         1024.0        4        4      326\n",
      "0.077637 0.061523         2048         2048.0        4        4      499\n",
      "0.060547 0.043457         4096         4096.0        4        4      169\n",
      "0.055908 0.051270         8192         8192.0        4        4      692\n",
      "0.043030 0.030151        16384        16384.0        4        4      390\n",
      "0.033295 0.023560        32768        32768.0        4        4      511\n",
      "0.023727 0.014160        65536        65536.0        4        4      279\n",
      "0.016899 0.010071       131072       131072.0        4        4      198\n",
      "0.012367 0.007835       262144       262144.0        4        4      209\n",
      "0.012344 0.012321       524288       524288.0        4        4      207\n",
      "0.016707 0.021070      1048576      1048576.0        4        4      781\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1685275\n",
      "passes used = 1\n",
      "weighted example sum = 1685275.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.021164\n",
      "total feature number = 979724852\n",
      "logloss  = 0.13326\n",
      "accuracy = 0.97884\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model\n",
    "! vw -i model -t test -r pred\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с другими параметрами модели. Добавьте квадратичные взаимодействия между различными блоками признаков, измените параметры оптимизатора, добавьте регуляризацию и т.д. <br>\n",
    "Выберите не менее трех параметров (и дискретные, и непрерывные). Для каждого из них объясните, почему по вашему мнению его изменение может улучшить качество модели, подберите оптимальное значение. Можете перебрать несколько значений в цикле, но лучше воспользоваться [vw-hypersearch](https://github.com/JohnLangford/vowpal_wabbit/wiki/Using-vw-hypersearch) или [vw-hyperopt](https://github.com/JohnLangford/vowpal_wabbit/blob/master/utl/vw-hyperopt.py) ([статья на хабре](https://habrahabr.ru/company/dca/blog/272697/)). Удобночитаемый вывод и/или графики для разных значений параметров обязательны.\n",
    "\n",
    "Совсем необязательно добиваться наилучшего качества. Для нас важнее то, насколько хорошо вы разобрались с возможностями библиотеки и продемонстрировали это.\n",
    "\n",
    "\n",
    "Помогло ли добавление квадратичных взаимодействий? Каких групп признаков? Какие параметры повлияли на улучшение качества сильнее всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Приблизительная разбалловка:\n",
    "* 3 балла в верно реализованные функции\n",
    "* 1 балл за ответ на вопрос про параметры `--passes` и `-b` (с графиком/выводом)\n",
    "* 2 балла за эффективное нахождение наиболее значимых признаков\n",
    "* 1 балл за добавление своих признаков\n",
    "* 3 балла за финальную часть (квадратичные взаимодействия, подбор параметров, графики/вывод и комментарии)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "1976fc1dd32447629ba83787172d9f33": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "948692d2a80d404993c14e0ff736100e": {
     "views": [
      {
       "cell_index": 45
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
